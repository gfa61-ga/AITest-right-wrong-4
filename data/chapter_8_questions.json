[
  {
    "question": "Η Ενισχυτική Μάθηση (RL) εστιάζει στη δημιουργία συστημάτων που μαθαίνουν μέσω αλληλεπίδρασης με το περιβάλλον.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Η ενισχυτική μάθηση αφορά την ανάπτυξη συστημάτων που μπορούν να μαθαίνουν αυτόνομα μέσω δοκιμής και σφάλματος (trial-and-error)."
  },
  {
    "question": "Ο 'Πράκτορας' (Agent) είναι το περιβάλλον στο οποίο δρα το σύστημα.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "Λίστα (Πράκτορας)"
    },
    "right_answer": "Ο Πράκτορας είναι το υποκείμενο που λαμβάνει αποφάσεις, όχι το περιβάλλον."
  },
  {
    "question": "Η 'Πολιτική' (Policy) καθορίζει τη συμπεριφορά του πράκτορα σε κάθε κατάσταση.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "Λίστα (Στρατηγική/Policy)"
    },
    "right_answer": "Η πολιτική είναι η στρατηγική που ορίζει ποια ενέργεια θα εκτελέσει ο πράκτορας βάσει της τρέχουσας κατάστασης."
  },
  {
    "question": "Η Συνάρτηση Τιμής (Value Function) εκτιμά την άμεση ανταμοιβή μιας ενέργειας.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 235-236",
      "paragraph": "Λίστα (Συνάρτηση Τιμής)"
    },
    "right_answer": "Η Συνάρτηση Τιμής εκτιμά την αναμενόμενη *συνολική* ανταμοιβή σε βάθος χρόνου, όχι μόνο την άμεση."
  },
  {
    "question": "Η Βαθιά Ενισχυτική Μάθηση (Deep RL) χρησιμοποιεί νευρωνικά δίκτυα για την αναπαράσταση στρατηγικών.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος (DRL)"
    },
    "right_answer": "Η Deep RL ενσωματώνει βαθιά νευρωνικά δίκτυα για να διαχειριστεί πολύπλοκα προβλήματα."
  },
  {
    "question": "Τα Deep Q-Networks (DQN) χρησιμοποιούνται για την εκτίμηση συναρτήσεων τιμής.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος (DRL)"
    },
    "right_answer": "Τα DQN χρησιμοποιούνται για να εκτιμήσουν τις συναρτήσεις τιμής σε περιβάλλοντα με μεγάλο χώρο καταστάσεων."
  },
  {
    "question": "Οι μέθοδοι βαθμίδας πολιτικής (Policy Gradient) βελτιστοποιούν πρώτα την αξία των καταστάσεων.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "Τελευταία παράγραφος"
    },
    "right_answer": "Οι μέθοδοι βαθμίδας πολιτικής βελτιστοποιούν *απευθείας* τη στρατηγική, χωρίς απαραίτητα να εκτιμούν πρώτα αξίες."
  },
  {
    "question": "Τα μοντέλα Actor-Critic αποτελούνται από δύο κύρια μέρη: τον ηθοποιό και τον κριτή.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "3η παράγραφος (Actor-Critic)"
    },
    "right_answer": "Ο Actor επιλέγει τη δράση και ο Critic αξιολογεί την ποιότητα της δράσης αυτής."
  },
  {
    "question": "Στα Συστήματα Πολλαπλών Πρακτόρων (Multi-Agent Systems), οι πράκτορες λειτουργούν πάντα ανεξάρτητα.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "2η παράγραφος (Συνεργασία και Ανταγωνισμός)"
    },
    "right_answer": "Οι πράκτορες μπορούν να συνεργάζονται ή να ανταγωνίζονται, επηρεάζοντας ο ένας τις αποφάσεις του άλλου."
  },
  {
    "question": "Η Ιεραρχική Ενισχυτική Μάθηση (HRL) διασπά τα προβλήματα σε μικρότερες υπο-εργασίες.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "4η παράγραφος (HRL)"
    },
    "right_answer": "Η HRL οργανώνει τη μάθηση σε επίπεδα, επιτρέποντας την επίλυση σύνθετων προβλημάτων μέσω αποδόμησης."
  },
  {
    "question": "Το δίλημμα 'Εξερεύνηση vs Εκμετάλλευση' αφορά την επιλογή μεταξύ δοκιμής νέων ενεργειών και χρήσης γνωστών.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 241",
      "paragraph": "1η παράγραφος (Exploration vs Exploitation)"
    },
    "right_answer": "Αναφέρεται στην ισορροπία μεταξύ της αναζήτησης νέων στρατηγικών και της αξιοποίησης των ήδη γνωστών."
  },
  {
    "question": "Η 'Αραιή Ανταμοιβή' (Sparse Reward) διευκολύνει τη διαδικασία μάθησης του πράκτορα.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "2η παράγραφος (Αβεβαιότητα)"
    },
    "right_answer": "Η αραιή ανταμοιβή δυσκολεύει τη μάθηση, καθώς ο πράκτορας λαμβάνει σπάνια ανατροφοδότηση για τις πράξεις του."
  },
  {
    "question": "Η Ενισχυτική Μάθηση χρησιμοποιείται για τη δυναμική διαχείριση ενεργειακών δικτύων.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "2η παράγραφος (Εφαρμογές)"
    },
    "right_answer": "Επιτρέπει την προσαρμογή της ροής ενέργειας σε πραγματικό χρόνο για βελτιστοποίηση της κατανάλωσης."
  },
  {
    "question": "Τα αυτόνομα οχήματα δεν χρησιμοποιούν ενισχυτική μάθηση για τη λήψη αποφάσεων.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "3η παράγραφος (Αυτόνομα Οχήματα)"
    },
    "right_answer": "Η ενισχυτική μάθηση είναι κεντρική στην εκπαίδευση αυτόνομων οχημάτων για πλοήγηση και ασφάλεια."
  },
  {
    "question": "Η Μηδενική Μάθηση (Zero-Shot Learning) επιτρέπει σε έναν πράκτορα να αντιμετωπίσει καταστάσεις που δεν έχει ξαναδεί.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "3η παράγραφος (Προσαρμοστικότητα)"
    },
    "right_answer": "Η ικανότητα γενίκευσης σε άγνωστες καταστάσεις είναι στόχος προηγμένων συστημάτων RL."
  },
  {
    "question": "Στη μελέτη περίπτωσης (σελ. 245), το σύστημα διαχείρισης ενέργειας μείωσε το λειτουργικό κόστος κατά 50%.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "2η παράγραφος (Αποτελέσματα)"
    },
    "right_answer": "Το σύστημα πέτυχε μείωση του κόστους κατά 15-20%, όχι 50%."
  },
  {
    "question": "Η Ενισχυτική Μάθηση μπορεί να εφαρμοστεί στη βιομηχανική αυτοματοποίηση για προληπτική συντήρηση.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Βοηθά στην πρόβλεψη βλαβών και τη βελτιστοποίηση της παραγωγής."
  },
  {
    "question": "Ο αλγόριθμος Proximal Policy Optimization (PPO) ανήκει στις μεθόδους βαθμίδας πολιτικής.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Το PPO είναι ένας δημοφιλής αλγόριθμος που βελτιώνει τη σταθερότητα της εκπαίδευσης."
  },
  {
    "question": "Η 'κατάρα της διαστατικότητας' (curse of dimensionality) αναφέρεται στην έλλειψη δεδομένων.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "1η παράγραφος (Πολυπλοκότητα)"
    },
    "right_answer": "Αναφέρεται στην εκθετική αύξηση της πολυπλοκότητας καθώς αυξάνονται οι παράμετροι του προβλήματος."
  },
  {
    "question": "Τα συστήματα ελέγχου φωτεινών σηματοδοτών μπορούν να βελτιστοποιηθούν με ενισχυτική μάθηση.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "2η παράγραφος (Έξυπνες Πόλεις)"
    },
    "right_answer": "Μπορούν να προσαρμόζουν τους χρόνους των φαναριών βάσει της τρέχουσας κίνησης."
  },
  {
    "question": "Η ανταμοιβή (Reward) δίνεται στον πράκτορα πάντα πριν εκτελέσει την ενέργεια.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Η ανταμοιβή δίνεται *μετά* την εκτέλεση της ενέργειας ως ανατροφοδότηση."
  },
  {
    "question": "Το Deep Q-Network (DQN) συνδυάζει Q-Learning με βαθιά νευρωνικά δίκτυα.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος"
    },
    "right_answer": "Είναι ο συνδυασμός του κλασικού αλγορίθμου Q-Learning με deep learning."
  },
  {
    "question": "Στα πολυπρακτορικά συστήματα, η μάθηση είναι πιο εύκολη επειδή το περιβάλλον είναι στατικό.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "3η παράγραφος"
    },
    "right_answer": "Το περιβάλλον είναι δυναμικό και μη στατικό, καθώς οι ενέργειες ενός πράκτορα επηρεάζουν τους άλλους."
  },
  {
    "question": "Η Ιεραρχική Ενισχυτική Μάθηση επιτρέπει τη χρήση 'αφαιρέσεων' (abstractions) για τη λήψη αποφάσεων.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "4η παράγραφος"
    },
    "right_answer": "Λειτουργεί σε διαφορετικά επίπεδα αφαίρεσης, από υψηλού επιπέδου στόχους έως συγκεκριμένες ενέργειες."
  },
  {
    "question": "Η 'διαμόρφωση ανταμοιβής' (reward shaping) δεν επηρεάζει την ταχύτητα μάθησης.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "2η παράγραφος"
    },
    "right_answer": "Η σωστή σχεδίαση των ανταμοιβών είναι κρίσιμη για την καθοδήγηση και την επιτάχυνση της μάθησης."
  },
  {
    "question": "Στη μελέτη περίπτωσης (σελ. 245), χρησιμοποιήθηκε ο αλγόριθμος PPO για τη διαχείριση μπαταριών.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 246",
      "paragraph": "1η παράγραφος (Υλοποίηση)"
    },
    "right_answer": "Χρησιμοποιήθηκε ο Proximal Policy Optimization (PPO) για τη λήψη αποφάσεων φόρτισης/εκφόρτισης."
  },
  {
    "question": "Οι αλγόριθμοι RL δεν μπορούν να εφαρμοστούν σε προβλήματα ρομποτικής.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος (DRL)"
    },
    "right_answer": "Η ρομποτική είναι ένας από τους κύριους τομείς εφαρμογής της ενισχυτικής μάθησης."
  },
  {
    "question": "Η 'πολιτική' (policy) μπορεί να είναι στοχαστική, δηλαδή να δίνει πιθανότητες για κάθε ενέργεια.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "Λίστα (Πολιτική - context)"
    },
    "right_answer": "Μια πολιτική μπορεί να επιλέγει ενέργειες βάσει πιθανοτήτων (στοχαστική) ή ντετερμινιστικά."
  },
  {
    "question": "Τα συστήματα RL απαιτούν πάντα τεράστια υπολογιστική ισχύ.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Η εκπαίδευση, ειδικά σε πολύπλοκα περιβάλλοντα, είναι υπολογιστικά απαιτητική."
  },
  {
    "question": "Η 'ασφάλεια' (safety) είναι βασικό ζήτημα στην εφαρμογή RL σε πραγματικά συστήματα.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "1η παράγραφος (Ηθικά θέματα)"
    },
    "right_answer": "Η διασφάλιση ότι ο πράκτορας δεν θα προβεί σε επικίνδυνες ενέργειες κατά την εξερεύνηση είναι κρίσιμη."
  },
  {
    "question": "Στα Multi-Agent Systems, όλοι οι πράκτορες έχουν πάντα τον ίδιο κοινό στόχο.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 239",
      "paragraph": "2η παράγραφος"
    },
    "right_answer": "Μπορεί να έχουν αντικρουόμενους στόχους (ανταγωνισμός) ή κοινούς (συνεργασία)."
  },
  {
    "question": "Το AlphaGo είναι παράδειγμα συστήματος που χρησιμοποιεί Ενισχυτική Μάθηση.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 155",
      "paragraph": "2η παράγραφος (Κεφάλαιο 5 - αναφορά στο 8)"
    },
    "right_answer": "Αν και η λεπτομερής αναφορά είναι στο κεφ. 5, το κεφ. 8 αναπτύσσει τις τεχνικές που το κατέστησαν δυνατό (Deep RL)."
  },
  {
    "question": "Η Ενισχυτική Μάθηση δεν μπορεί να χρησιμοποιηθεί για εξατομίκευση περιεχομένου.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "Context εφαρμογών"
    },
    "right_answer": "Χρησιμοποιείται ευρέως σε συστήματα συστάσεων για προσωποποίηση."
  },
  {
    "question": "Ο Critic στις μεθόδους Actor-Critic αξιολογεί την κατάσταση.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 238",
      "paragraph": "3η παράγραφος"
    },
    "right_answer": "Ο Critic παρέχει εκτίμηση της αξίας της κατάστασης ή της ενέργειας."
  },
  {
    "question": "Η 'μεταφορά μάθησης' (transfer learning) δεν εφαρμόζεται στην Ενισχυτική Μάθηση.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 242",
      "paragraph": "3η παράγραφος"
    },
    "right_answer": "Είναι σημαντική τεχνική για την επιτάχυνση της εκπαίδευσης σε νέα αλλά παρόμοια καθήκοντα."
  },
  {
    "question": "Τα μικροδίκτυα (Microgrids) μπορούν να λειτουργούν αυτόνομα από το κεντρικό δίκτυο.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 245",
      "paragraph": "1η παράγραφος (Μελέτη περίπτωσης)"
    },
    "right_answer": "Τα μικροδίκτυα έχουν τη δυνατότητα να λειτουργούν συνδεδεμένα ή απομονωμένα (island mode)."
  },
  {
    "question": "Η μελέτη περίπτωσης SmartEnergy (σελ. 245) αφορούσε εργοστάσιο αυτοκινήτων.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 245",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Αφορούσε την ανάπτυξη συστήματος διαχείρισης ενέργειας για μικροδίκτυα."
  },
  {
    "question": "Η 'εξομάλυνση εμπειρίας' (experience replay) χρησιμοποιείται για τη σταθεροποίηση της εκπαίδευσης στα DQN.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 237",
      "paragraph": "2η παράγραφος (Context DQN)"
    },
    "right_answer": "Επιτρέπει στον πράκτορα να μαθαίνει από παλαιότερες εμπειρίες, σπάζοντας τη συσχέτιση διαδοχικών δεδομένων."
  },
  {
    "question": "Η Ενισχυτική Μάθηση απαιτεί πάντα δεδομένα με ετικέτες από ανθρώπους.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Βασίζεται στην αυτο-εκπαίδευση μέσω αλληλεπίδρασης και ανταμοιβών, όχι σε δεδομένα με ετικέτες."
  },
  {
    "question": "Η 'αναγνώριση προτύπων' είναι ο μοναδικός στόχος της Ενισχυτικής Μάθησης.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Ο κύριος στόχος είναι η λήψη βέλτιστων αποφάσεων, όχι απλά η αναγνώριση."
  },
  {
    "question": "Οι αλγόριθμοι RL μπορούν να προσαρμοστούν σε αλλαγές του περιβάλλοντος σε πραγματικό χρόνο.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "2η παράγραφος"
    },
    "right_answer": "Η δυνατότητα προσαρμογής (adaptability) είναι βασικό χαρακτηριστικό τους."
  },
  {
    "question": "Στο σκάκι, το περιβάλλον θεωρείται πλήρως παρατηρήσιμο.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "Λίστα (Περιβάλλον - context)"
    },
    "right_answer": "Ο παίκτης έχει πλήρη εικόνα της κατάστασης του παιχνιδιού ανά πάσα στιγμή."
  },
  {
    "question": "Η 'συνάρτηση πολιτικής' χαρτογραφεί καταστάσεις σε ενέργειες.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 235",
      "paragraph": "Λίστα (Πολιτική)"
    },
    "right_answer": "Ορίζει τι πρέπει να κάνει ο πράκτορας σε κάθε δεδομένη κατάσταση."
  },
  {
    "question": "Η Ενισχυτική Μάθηση είναι υποκατηγορία της Μη Επιβλεπόμενης Μάθησης.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 234",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Είναι ξεχωριστή κατηγορία μηχανικής μάθησης, δίπλα στην Επιβλεπόμενη και τη Μη Επιβλεπόμενη."
  },
  {
    "question": "Η ενσωμάτωση Ανανεώσιμων Πηγών Ενέργειας (ΑΠΕ) στα μικροδίκτυα αυξάνει την πολυπλοκότητα διαχείρισης.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 245",
      "paragraph": "2η παράγραφος"
    },
    "right_answer": "Λόγω της μεταβλητότητας της παραγωγής (π.χ. ήλιος, άνεμος), η διαχείριση γίνεται πιο δύσκολη."
  },
  {
    "question": "Ο αλγόριθμος A* είναι αλγόριθμος Ενισχυτικής Μάθησης.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 126 (Κεφάλαιο 4 - για σύγκριση)"
    },
    "right_answer": "Ο A* είναι αλγόριθμος αναζήτησης διαδρομής, όχι Ενισχυτικής Μάθησης (όπως ο Q-Learning)."
  },
  {
    "question": "Η εκπαίδευση πρακτόρων σε προσομοιωμένα περιβάλλοντα μειώνει τον κίνδυνο ζημιάς στον πραγματικό κόσμο.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 243",
      "paragraph": "1η παράγραφος (Ασφάλεια)"
    },
    "right_answer": "Η προσομοίωση επιτρέπει την εκπαίδευση χωρίς φυσικές συνέπειες από λάθη."
  },
  {
    "question": "Τα συστήματα ελέγχου βιομηχανικών ρομπότ απαιτούν υψηλή ακρίβεια και ταχύτητα.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "easy",
    "reference": {
      "page": "σελ. 244",
      "paragraph": "1η παράγραφος"
    },
    "right_answer": "Η εφαρμογή στη βιομηχανία απαιτεί ρομπότ που λειτουργούν γρήγορα και με ακρίβεια."
  },
  {
    "question": "Η 'απομείωση' (discount factor) καθορίζει πόσο σημαντικές είναι οι μελλοντικές ανταμοιβές.",
    "answer": true,
    "chapter_number": 8,
    "difficulty": "hard",
    "reference": {
      "page": "σελ. 236",
      "paragraph": "Context (Συνάρτηση Τιμής)"
    },
    "right_answer": "Καθορίζει την παρούσα αξία των μελλοντικών ανταμοιβών (πόσο 'διορατικός' είναι ο πράκτορας)."
  },
  {
    "question": "Η Ενισχυτική Μάθηση δεν έχει εφαρμογή στον τομέα της Υγείας.",
    "answer": false,
    "chapter_number": 8,
    "difficulty": "medium",
    "reference": {
      "page": "σελ. 155",
      "paragraph": "2η παράγραφος (Κεφάλαιο 5 - γενική γνώση στο βιβλίο)"
    },
    "right_answer": "Χρησιμοποιείται για εξατομικευμένη θεραπεία και ρομποτική χειρουργική."
  }
]
